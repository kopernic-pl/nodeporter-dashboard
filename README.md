# NodePorter

![App Screenshot](./app-screenshot.png)
 Kubernetes Services Dashboard

A dashboard for viewing your local home lab Kubernetes cluster networking‚Äî**no hosts file editing or custom DNS required!**

---

> **Note:** This project was created and iteratively developed using AI assistance, enabling rapid prototyping and high-quality automation.

---

## üöÄ Project Background

This project was conceived as an experiment to leverage generative AI (GenAI) for real-world software development, while also solving a common pain point for home lab Kubernetes users:

> **How can I remember Kubernetes services nodeports, without editing `/etc/hosts` or running my own DNS for ingress?**

NodePorter provides a user-friendly, retro‚â•-styled dashboard that discovers and displays all your cluster services (and some nodes data), making it easy to remember and access NodePorts, and more‚Äîall with zero manual networking hacks.

---

## ‚ú® Features

- **Environment-aware banner:** Instantly see if you‚Äôre running in-cluster or local/dev mode.
- **Kubernetes Service Table:** List all services, types, ports, and direct NodePort links.
- **Cluster Node Summary:** See node count, total CPU, and memory at a glance.
- **No hosts file or DNS hacks:** Access services using real node IPs‚Äîno manual setup required.
- **Retro UI:** Styled with 8-bit fonts and vibrant colors for fun and clarity.
- **AI-assisted development:** The codebase was built and refactored with the help of generative AI tools for rapid iteration.

---

## üö¶ How to Run/Use

### Running locally

```sh
npm install
npm run dev
```

- Open [http://localhost:3000](http://localhost:3000) in your browser.

### Running container

```sh
docker run -d -p 3000:3000 ghcr.io/kopernic-pl/nodeporter-dashboard
```

- Open [http://localhost:3000](http://localhost:3000) in your browser.

### Running with Helm

You can deploy NodePorter to your Kubernetes cluster using the published Helm chart from the GitHub Container Registry (GHCR).

#### Prerequisites

- Helm 3.x installed ([installation guide](https://helm.sh/docs/intro/install/))
- Access to a Kubernetes cluster (e.g., minikube, kind, k3s, or remote)

#### 1. Add the OCI Registry (one time)

```sh
helm registry login ghcr.io
```

#### 2. Install the Chart

Check for the latest version on [GHCR NodePorter Helm Chart](https://github.com/orgs/kopernic-pl/packages/container/package/charts%2Fnodeporter).

```sh
helm install nodeporter oci://ghcr.io/kopernic-pl/charts/nodeporter \
  --version <latest-version> \
  --set service.type=NodePort \
  --set service.nodePort=30080 # Optional: set a specific NodePort
```

- By default, the app will be available on the assigned NodePort of your cluster nodes.
- You can override any value from the chart using `--set key=value` or by providing a custom `values.yaml` with `-f values.yaml`.

#### 3. Upgrade

To upgrade to a new version:

```sh
helm upgrade nodeporter oci://ghcr.io/kopernic-pl/charts/nodeporter \
  --version <latest-version>
```

#### 4. Uninstall

To remove the deployment:

```sh
helm uninstall nodeporter
```

#### 5. Customization

- See the chart's default values ([values.yaml](https://github.com/kopernic-pl/nodeporter/blob/main/charts/nodeporter/values.yaml)) for configuration options (replica count, resources, etc).
- Example: Change service type to `ClusterIP` or set resource limits.

For more, see the [Helm documentation](https://helm.sh/docs/).

---

## üßë‚Äçüíª Getting Started with Dev

### Dev prerequisites

- Node.js v18+ (tested on v22)
- Access to a Kubernetes cluster (local or remote)

---

## üè° Home Lab Use Case

- Deploy this dashboard to your local cluster (e.g., k3s, kind, minikube).
- No need to edit `/etc/hosts` or run CoreDNS tweaks‚Äîjust use the NodePort links provided.
- Works great for small teams or home labs wanting simple services and cluster size overview.

---

## ü§ñ GenAI Approach

This project was iteratively built and improved using generative AI (Cascade, GPT-4, etc.), showcasing:

- Rapid prototyping of UI and API features
- Automated code refactoring and dependency management
- AI-driven troubleshooting and test creation

---

## üì¶ Project Structure

- `.github/` - GitHub configuration and workflows
- `ops/` ‚Äî Deployment and Dockerization scripts
- `pages/` ‚Äî Next.js pages and API routes (including `api/` for backend endpoints)
- `public/` ‚Äî Static assets (icons, manifest, etc.)
- `styles/` ‚Äî Global and component CSS
- `utils/` ‚Äî Utility/helper functions (e.g., logging)
- `__tests__/` ‚Äî Jest tests for API and frontend
- `sbom.spdx.json` ‚Äî Software Bill of Materials (SBOM) generated by CI and attached to GitHub Releases (see below)

---

## üôè Credits

- [Next.js](https://nextjs.org/)
- [@kubernetes/client-node](https://github.com/kubernetes-client/javascript)
- [styled-components](https://styled-components.com/)
- [@fontsource/press-start-2p](https://fontsource.org/fonts/press-start-2p)
- GenAI for development support

---

## üìù Software Bill of Materials (SBOM) & Provenance Attestation

A Software Bill of Materials (SBOM) is automatically generated as part of the CI workflow and attached to every container image published to GHCR. The SBOM is created in [SPDX JSON](https://spdx.dev/specifications/) format using GitHub Actions and is stored as an OCI artifact alongside the image in the GitHub Container Registry (GHCR). This provides a machine-readable list of all dependencies for compliance, security, and transparency.

- **How to access:**
  - The SBOM can be viewed in the "Provenance" or "SBOM" tab of the container image on GitHub, or programmatically using tools like `cosign` or `oras`.
  - Example to download SBOM using `cosign`:

    ```sh
    cosign download sbom ghcr.io/kopernic-pl/nodeporter-dashboard:latest
    ```

  - Older releases may also have the SBOM attached as a GitHub Release asset (as `sbom.spdx.json`).

## üõ°Ô∏è Container Provenance & Attestation

Every container image published to GHCR by our CI/CD pipeline includes a signed provenance attestation (SLSA-compliant) generated by GitHub Actions. This attestation proves the image was built by our trusted CI process and includes details about the build (commit, workflow, inputs, etc.).

- **How to verify provenance:**
  - In the GitHub UI: Open the container image page in GHCR and look for the "Provenance" tab.
  - Using `cosign` CLI:

    ```sh
    cosign verify-attestation ghcr.io/kopernic-pl/nodeporter-dashboard:latest \
      --certificate-identity-regexp 'github.com/kopernic-pl/nodeporter-dashboard/.github/workflows/manual-release.yml@refs/heads/main' \
      --certificate-oidc-issuer 'https://token.actions.githubusercontent.com'
    ```

  - See [GitHub's documentation on container provenance](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry/about-container-image-signing-and-provenance) for more details.

These features help ensure the security and transparency of our supply chain for all users and integrators.

---

## üìù License

MIT‚Äîwith a cookie twist üç™
